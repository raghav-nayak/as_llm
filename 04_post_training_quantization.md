### Post Training Quantization(PTQ)
- after model is trained, we can apply PTQ

![[Pasted image 20240701220454.png]]

PTQ process
- Weight Quantization
	- Higher Precision(32 bit) -> +-3.4x10<sup>38</sup>
	- Lower precision(8 bit) -> -128 to 127
- Activation Quantization
	- activations -> outputs generated by the neurons or nodes in each layer of the network
- Determining Quantization Range
	- Static calibration
		- Happens offline and **pre-inference**
	- Dynamic calibration
		- Happens **during **
- 
